{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Régression linéaire multiple<h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des bibiotheques\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import  accuracy_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "R&D Spend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Administration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Marketing Spend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "State",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Profit",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b712ca63-e265-449c-9df7-67bbaf60aea9",
       "rows": [
        [
         "0",
         "165349.2",
         "136897.8",
         "471784.1",
         "New York",
         "192261.83"
        ],
        [
         "1",
         "162597.7",
         "151377.59",
         "443898.53",
         "California",
         "191792.06"
        ],
        [
         "2",
         "153441.51",
         "101145.55",
         "407934.54",
         "Florida",
         "191050.39"
        ],
        [
         "3",
         "144372.41",
         "118671.85",
         "383199.62",
         "New York",
         "182901.99"
        ],
        [
         "4",
         "142107.34",
         "91391.77",
         "366168.42",
         "Florida",
         "166187.94"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PositionSalary = pd.read_csv(\"./../../Datasets/Position_Salaries.csv\")\n",
    "\n",
    "PositionSalary.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Prétraitement des données</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R&D Spend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Administration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Marketing Spend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Profit",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6517379c-6cb2-40f8-92d0-1ab59420a013",
       "rows": [
        [
         "count",
         "50.0",
         "50.0",
         "50.0",
         "50.0"
        ],
        [
         "mean",
         "73721.6156",
         "121344.63960000001",
         "211025.09780000002",
         "112012.63920000002"
        ],
        [
         "std",
         "45902.25648230753",
         "28017.802755488683",
         "122290.31072584528",
         "40306.18033765055"
        ],
        [
         "min",
         "0.0",
         "51283.14",
         "0.0",
         "14681.4"
        ],
        [
         "25%",
         "39936.37",
         "103730.875",
         "129300.1325",
         "90138.9025"
        ],
        [
         "50%",
         "73051.08",
         "122699.795",
         "212716.24",
         "107978.19"
        ],
        [
         "75%",
         "101602.8",
         "144842.18",
         "299469.08499999996",
         "139765.97749999998"
        ],
        [
         "max",
         "165349.2",
         "182645.56",
         "471784.1",
         "192261.83"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73721.615600</td>\n",
       "      <td>121344.639600</td>\n",
       "      <td>211025.097800</td>\n",
       "      <td>112012.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45902.256482</td>\n",
       "      <td>28017.802755</td>\n",
       "      <td>122290.310726</td>\n",
       "      <td>40306.180338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>51283.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14681.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39936.370000</td>\n",
       "      <td>103730.875000</td>\n",
       "      <td>129300.132500</td>\n",
       "      <td>90138.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73051.080000</td>\n",
       "      <td>122699.795000</td>\n",
       "      <td>212716.240000</td>\n",
       "      <td>107978.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101602.800000</td>\n",
       "      <td>144842.180000</td>\n",
       "      <td>299469.085000</td>\n",
       "      <td>139765.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>165349.200000</td>\n",
       "      <td>182645.560000</td>\n",
       "      <td>471784.100000</td>\n",
       "      <td>192261.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           R&D Spend  Administration  Marketing Spend         Profit\n",
       "count      50.000000       50.000000        50.000000      50.000000\n",
       "mean    73721.615600   121344.639600    211025.097800  112012.639200\n",
       "std     45902.256482    28017.802755    122290.310726   40306.180338\n",
       "min         0.000000    51283.140000         0.000000   14681.400000\n",
       "25%     39936.370000   103730.875000    129300.132500   90138.902500\n",
       "50%     73051.080000   122699.795000    212716.240000  107978.190000\n",
       "75%    101602.800000   144842.180000    299469.085000  139765.977500\n",
       "max    165349.200000   182645.560000    471784.100000  192261.830000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StartupsData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification que chaque colonne ne contient pas de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StartupsData[\"R&D Spend\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StartupsData[\"Administration\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StartupsData[\"Marketing Spend\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StartupsData[\"State\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StartupsData[\"Profit\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encodage de la colonne State avec le OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "oneHotEncoder = OneHotEncoder()\n",
    "\n",
    "StartupsData[\"State\"] = oneHotEncoder.fit_transform(StartupsData.loc[:, [\"State\"]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "R&D Spend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Administration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Marketing Spend",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "State",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Profit",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e905bb73-d3a1-4d46-b672-0da2978706d9",
       "rows": [
        [
         "0",
         "165349.2",
         "136897.8",
         "471784.1",
         "0.0",
         "192261.83"
        ],
        [
         "1",
         "162597.7",
         "151377.59",
         "443898.53",
         "1.0",
         "191792.06"
        ],
        [
         "2",
         "153441.51",
         "101145.55",
         "407934.54",
         "0.0",
         "191050.39"
        ],
        [
         "3",
         "144372.41",
         "118671.85",
         "383199.62",
         "0.0",
         "182901.99"
        ],
        [
         "4",
         "142107.34",
         "91391.77",
         "366168.42",
         "0.0",
         "166187.94"
        ],
        [
         "5",
         "131876.9",
         "99814.71",
         "362861.36",
         "0.0",
         "156991.12"
        ],
        [
         "6",
         "134615.46",
         "147198.87",
         "127716.82",
         "1.0",
         "156122.51"
        ],
        [
         "7",
         "130298.13",
         "145530.06",
         "323876.68",
         "0.0",
         "155752.6"
        ],
        [
         "8",
         "120542.52",
         "148718.95",
         "311613.29",
         "0.0",
         "152211.77"
        ],
        [
         "9",
         "123334.88",
         "108679.17",
         "304981.62",
         "1.0",
         "149759.96"
        ],
        [
         "10",
         "101913.08",
         "110594.11",
         "229160.95",
         "0.0",
         "146121.95"
        ],
        [
         "11",
         "100671.96",
         "91790.61",
         "249744.55",
         "1.0",
         "144259.4"
        ],
        [
         "12",
         "93863.75",
         "127320.38",
         "249839.44",
         "0.0",
         "141585.52"
        ],
        [
         "13",
         "91992.39",
         "135495.07",
         "252664.93",
         "1.0",
         "134307.35"
        ],
        [
         "14",
         "119943.24",
         "156547.42",
         "256512.92",
         "0.0",
         "132602.65"
        ],
        [
         "15",
         "114523.61",
         "122616.84",
         "261776.23",
         "0.0",
         "129917.04"
        ],
        [
         "16",
         "78013.11",
         "121597.55",
         "264346.06",
         "1.0",
         "126992.93"
        ],
        [
         "17",
         "94657.16",
         "145077.58",
         "282574.31",
         "0.0",
         "125370.37"
        ],
        [
         "18",
         "91749.16",
         "114175.79",
         "294919.57",
         "0.0",
         "124266.9"
        ],
        [
         "19",
         "86419.7",
         "153514.11",
         "0.0",
         "0.0",
         "122776.86"
        ],
        [
         "20",
         "76253.86",
         "113867.3",
         "298664.47",
         "1.0",
         "118474.03"
        ],
        [
         "21",
         "78389.47",
         "153773.43",
         "299737.29",
         "0.0",
         "111313.02"
        ],
        [
         "22",
         "73994.56",
         "122782.75",
         "303319.26",
         "0.0",
         "110352.25"
        ],
        [
         "23",
         "67532.53",
         "105751.03",
         "304768.73",
         "0.0",
         "108733.99"
        ],
        [
         "24",
         "77044.01",
         "99281.34",
         "140574.81",
         "0.0",
         "108552.04"
        ],
        [
         "25",
         "64664.71",
         "139553.16",
         "137962.62",
         "1.0",
         "107404.34"
        ],
        [
         "26",
         "75328.87",
         "144135.98",
         "134050.07",
         "0.0",
         "105733.54"
        ],
        [
         "27",
         "72107.6",
         "127864.55",
         "353183.81",
         "0.0",
         "105008.31"
        ],
        [
         "28",
         "66051.52",
         "182645.56",
         "118148.2",
         "0.0",
         "103282.38"
        ],
        [
         "29",
         "65605.48",
         "153032.06",
         "107138.38",
         "0.0",
         "101004.64"
        ],
        [
         "30",
         "61994.48",
         "115641.28",
         "91131.24",
         "0.0",
         "99937.59"
        ],
        [
         "31",
         "61136.38",
         "152701.92",
         "88218.23",
         "0.0",
         "97483.56"
        ],
        [
         "32",
         "63408.86",
         "129219.61",
         "46085.25",
         "1.0",
         "97427.84"
        ],
        [
         "33",
         "55493.95",
         "103057.49",
         "214634.81",
         "0.0",
         "96778.92"
        ],
        [
         "34",
         "46426.07",
         "157693.92",
         "210797.67",
         "1.0",
         "96712.8"
        ],
        [
         "35",
         "46014.02",
         "85047.44",
         "205517.64",
         "0.0",
         "96479.51"
        ],
        [
         "36",
         "28663.76",
         "127056.21",
         "201126.82",
         "0.0",
         "90708.19"
        ],
        [
         "37",
         "44069.95",
         "51283.14",
         "197029.42",
         "1.0",
         "89949.14"
        ],
        [
         "38",
         "20229.59",
         "65947.93",
         "185265.1",
         "0.0",
         "81229.06"
        ],
        [
         "39",
         "38558.51",
         "82982.09",
         "174999.3",
         "1.0",
         "81005.76"
        ],
        [
         "40",
         "28754.33",
         "118546.05",
         "172795.67",
         "1.0",
         "78239.91"
        ],
        [
         "41",
         "27892.92",
         "84710.77",
         "164470.71",
         "0.0",
         "77798.83"
        ],
        [
         "42",
         "23640.93",
         "96189.63",
         "148001.11",
         "1.0",
         "71498.49"
        ],
        [
         "43",
         "15505.73",
         "127382.3",
         "35534.17",
         "0.0",
         "69758.98"
        ],
        [
         "44",
         "22177.74",
         "154806.14",
         "28334.72",
         "1.0",
         "65200.33"
        ],
        [
         "45",
         "1000.23",
         "124153.04",
         "1903.93",
         "0.0",
         "64926.08"
        ],
        [
         "46",
         "1315.46",
         "115816.21",
         "297114.46",
         "0.0",
         "49490.75"
        ],
        [
         "47",
         "0.0",
         "135426.92",
         "0.0",
         "1.0",
         "42559.73"
        ],
        [
         "48",
         "542.05",
         "51743.15",
         "0.0",
         "0.0",
         "35673.41"
        ],
        [
         "49",
         "0.0",
         "116983.8",
         "45173.06",
         "1.0",
         "14681.4"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 50
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend  State     Profit\n",
       "0   165349.20       136897.80        471784.10    0.0  192261.83\n",
       "1   162597.70       151377.59        443898.53    1.0  191792.06\n",
       "2   153441.51       101145.55        407934.54    0.0  191050.39\n",
       "3   144372.41       118671.85        383199.62    0.0  182901.99\n",
       "4   142107.34        91391.77        366168.42    0.0  166187.94\n",
       "5   131876.90        99814.71        362861.36    0.0  156991.12\n",
       "6   134615.46       147198.87        127716.82    1.0  156122.51\n",
       "7   130298.13       145530.06        323876.68    0.0  155752.60\n",
       "8   120542.52       148718.95        311613.29    0.0  152211.77\n",
       "9   123334.88       108679.17        304981.62    1.0  149759.96\n",
       "10  101913.08       110594.11        229160.95    0.0  146121.95\n",
       "11  100671.96        91790.61        249744.55    1.0  144259.40\n",
       "12   93863.75       127320.38        249839.44    0.0  141585.52\n",
       "13   91992.39       135495.07        252664.93    1.0  134307.35\n",
       "14  119943.24       156547.42        256512.92    0.0  132602.65\n",
       "15  114523.61       122616.84        261776.23    0.0  129917.04\n",
       "16   78013.11       121597.55        264346.06    1.0  126992.93\n",
       "17   94657.16       145077.58        282574.31    0.0  125370.37\n",
       "18   91749.16       114175.79        294919.57    0.0  124266.90\n",
       "19   86419.70       153514.11             0.00    0.0  122776.86\n",
       "20   76253.86       113867.30        298664.47    1.0  118474.03\n",
       "21   78389.47       153773.43        299737.29    0.0  111313.02\n",
       "22   73994.56       122782.75        303319.26    0.0  110352.25\n",
       "23   67532.53       105751.03        304768.73    0.0  108733.99\n",
       "24   77044.01        99281.34        140574.81    0.0  108552.04\n",
       "25   64664.71       139553.16        137962.62    1.0  107404.34\n",
       "26   75328.87       144135.98        134050.07    0.0  105733.54\n",
       "27   72107.60       127864.55        353183.81    0.0  105008.31\n",
       "28   66051.52       182645.56        118148.20    0.0  103282.38\n",
       "29   65605.48       153032.06        107138.38    0.0  101004.64\n",
       "30   61994.48       115641.28         91131.24    0.0   99937.59\n",
       "31   61136.38       152701.92         88218.23    0.0   97483.56\n",
       "32   63408.86       129219.61         46085.25    1.0   97427.84\n",
       "33   55493.95       103057.49        214634.81    0.0   96778.92\n",
       "34   46426.07       157693.92        210797.67    1.0   96712.80\n",
       "35   46014.02        85047.44        205517.64    0.0   96479.51\n",
       "36   28663.76       127056.21        201126.82    0.0   90708.19\n",
       "37   44069.95        51283.14        197029.42    1.0   89949.14\n",
       "38   20229.59        65947.93        185265.10    0.0   81229.06\n",
       "39   38558.51        82982.09        174999.30    1.0   81005.76\n",
       "40   28754.33       118546.05        172795.67    1.0   78239.91\n",
       "41   27892.92        84710.77        164470.71    0.0   77798.83\n",
       "42   23640.93        96189.63        148001.11    1.0   71498.49\n",
       "43   15505.73       127382.30         35534.17    0.0   69758.98\n",
       "44   22177.74       154806.14         28334.72    1.0   65200.33\n",
       "45    1000.23       124153.04          1903.93    0.0   64926.08\n",
       "46    1315.46       115816.21        297114.46    0.0   49490.75\n",
       "47       0.00       135426.92             0.00    1.0   42559.73\n",
       "48     542.05        51743.15             0.00    0.0   35673.41\n",
       "49       0.00       116983.80         45173.06    1.0   14681.40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StartupsData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'aurons pas besoin de normaliser les données ici catr il s'agit d'une regression linéaire et les libraries le feront pour nous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StartupsData.iloc[:, :-1].values\n",
    "Y = StartupsData.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6534920e+05, 1.3689780e+05, 4.7178410e+05, 0.0000000e+00],\n",
       "       [1.6259770e+05, 1.5137759e+05, 4.4389853e+05, 1.0000000e+00],\n",
       "       [1.5344151e+05, 1.0114555e+05, 4.0793454e+05, 0.0000000e+00],\n",
       "       [1.4437241e+05, 1.1867185e+05, 3.8319962e+05, 0.0000000e+00],\n",
       "       [1.4210734e+05, 9.1391770e+04, 3.6616842e+05, 0.0000000e+00],\n",
       "       [1.3187690e+05, 9.9814710e+04, 3.6286136e+05, 0.0000000e+00],\n",
       "       [1.3461546e+05, 1.4719887e+05, 1.2771682e+05, 1.0000000e+00],\n",
       "       [1.3029813e+05, 1.4553006e+05, 3.2387668e+05, 0.0000000e+00],\n",
       "       [1.2054252e+05, 1.4871895e+05, 3.1161329e+05, 0.0000000e+00],\n",
       "       [1.2333488e+05, 1.0867917e+05, 3.0498162e+05, 1.0000000e+00],\n",
       "       [1.0191308e+05, 1.1059411e+05, 2.2916095e+05, 0.0000000e+00],\n",
       "       [1.0067196e+05, 9.1790610e+04, 2.4974455e+05, 1.0000000e+00],\n",
       "       [9.3863750e+04, 1.2732038e+05, 2.4983944e+05, 0.0000000e+00],\n",
       "       [9.1992390e+04, 1.3549507e+05, 2.5266493e+05, 1.0000000e+00],\n",
       "       [1.1994324e+05, 1.5654742e+05, 2.5651292e+05, 0.0000000e+00],\n",
       "       [1.1452361e+05, 1.2261684e+05, 2.6177623e+05, 0.0000000e+00],\n",
       "       [7.8013110e+04, 1.2159755e+05, 2.6434606e+05, 1.0000000e+00],\n",
       "       [9.4657160e+04, 1.4507758e+05, 2.8257431e+05, 0.0000000e+00],\n",
       "       [9.1749160e+04, 1.1417579e+05, 2.9491957e+05, 0.0000000e+00],\n",
       "       [8.6419700e+04, 1.5351411e+05, 0.0000000e+00, 0.0000000e+00],\n",
       "       [7.6253860e+04, 1.1386730e+05, 2.9866447e+05, 1.0000000e+00],\n",
       "       [7.8389470e+04, 1.5377343e+05, 2.9973729e+05, 0.0000000e+00],\n",
       "       [7.3994560e+04, 1.2278275e+05, 3.0331926e+05, 0.0000000e+00],\n",
       "       [6.7532530e+04, 1.0575103e+05, 3.0476873e+05, 0.0000000e+00],\n",
       "       [7.7044010e+04, 9.9281340e+04, 1.4057481e+05, 0.0000000e+00],\n",
       "       [6.4664710e+04, 1.3955316e+05, 1.3796262e+05, 1.0000000e+00],\n",
       "       [7.5328870e+04, 1.4413598e+05, 1.3405007e+05, 0.0000000e+00],\n",
       "       [7.2107600e+04, 1.2786455e+05, 3.5318381e+05, 0.0000000e+00],\n",
       "       [6.6051520e+04, 1.8264556e+05, 1.1814820e+05, 0.0000000e+00],\n",
       "       [6.5605480e+04, 1.5303206e+05, 1.0713838e+05, 0.0000000e+00],\n",
       "       [6.1994480e+04, 1.1564128e+05, 9.1131240e+04, 0.0000000e+00],\n",
       "       [6.1136380e+04, 1.5270192e+05, 8.8218230e+04, 0.0000000e+00],\n",
       "       [6.3408860e+04, 1.2921961e+05, 4.6085250e+04, 1.0000000e+00],\n",
       "       [5.5493950e+04, 1.0305749e+05, 2.1463481e+05, 0.0000000e+00],\n",
       "       [4.6426070e+04, 1.5769392e+05, 2.1079767e+05, 1.0000000e+00],\n",
       "       [4.6014020e+04, 8.5047440e+04, 2.0551764e+05, 0.0000000e+00],\n",
       "       [2.8663760e+04, 1.2705621e+05, 2.0112682e+05, 0.0000000e+00],\n",
       "       [4.4069950e+04, 5.1283140e+04, 1.9702942e+05, 1.0000000e+00],\n",
       "       [2.0229590e+04, 6.5947930e+04, 1.8526510e+05, 0.0000000e+00],\n",
       "       [3.8558510e+04, 8.2982090e+04, 1.7499930e+05, 1.0000000e+00],\n",
       "       [2.8754330e+04, 1.1854605e+05, 1.7279567e+05, 1.0000000e+00],\n",
       "       [2.7892920e+04, 8.4710770e+04, 1.6447071e+05, 0.0000000e+00],\n",
       "       [2.3640930e+04, 9.6189630e+04, 1.4800111e+05, 1.0000000e+00],\n",
       "       [1.5505730e+04, 1.2738230e+05, 3.5534170e+04, 0.0000000e+00],\n",
       "       [2.2177740e+04, 1.5480614e+05, 2.8334720e+04, 1.0000000e+00],\n",
       "       [1.0002300e+03, 1.2415304e+05, 1.9039300e+03, 0.0000000e+00],\n",
       "       [1.3154600e+03, 1.1581621e+05, 2.9711446e+05, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.3542692e+05, 0.0000000e+00, 1.0000000e+00],\n",
       "       [5.4205000e+02, 5.1743150e+04, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.1698380e+05, 4.5173060e+04, 1.0000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 5)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)  # Affiche la forme de X  \n",
    "print(Y.shape)  # Affiche la forme de Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appliquons la regression linéaire multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linearRegression = LinearRegression()\n",
    "\n",
    "linearRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103962.55391373, 132569.79621934, 133248.38608834,  72577.20448177,\n",
       "       179058.65635572, 114748.39099366,  66688.37917583,  98150.25103157])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = linearRegression.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97581277.90779126"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = mean_squared_error(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>BackWard Élimination</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Appliquons le BackWard Élimination pour eliminer les variables qui n'ont pas un grand imapct sur la variable dependante profit</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on va concatener le dataset avec une colonne de 1 a la premeiere colonne du dataset pour que on ait quelque chose de la forme :\n",
    "\n",
    "Y = b0*X0 + b1*X1 + b2*X2 + ... + bn*Xn\n",
    "\n",
    "ou Xi est la  variable independante \n",
    "bi est le coefficient \n",
    "Y est la variable dependante\n",
    "\n",
    "car au depat on avait:\n",
    "\n",
    "Y = b0 + b1*X1 + b2*X2 + ... + bn*Xn \n",
    "\n",
    "et donc comme on veut avoir le cofficient de chaque vaiable independante, on a pensé a ajouter une colonne de 1 au debut du dataset qui serait equivaut a X0 pour qu'on aiyt l'expression:  \n",
    "\n",
    "Y = b0*X0 + b1*X1 + b2*X2 + ... + bn*Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.6534920e+05, 1.3689780e+05, 4.7178410e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.6259770e+05, 1.5137759e+05, 4.4389853e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.5344151e+05, 1.0114555e+05, 4.0793454e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.4437241e+05, 1.1867185e+05, 3.8319962e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.4210734e+05, 9.1391770e+04, 3.6616842e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.3187690e+05, 9.9814710e+04, 3.6286136e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.3461546e+05, 1.4719887e+05, 1.2771682e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.3029813e+05, 1.4553006e+05, 3.2387668e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.2054252e+05, 1.4871895e+05, 3.1161329e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.2333488e+05, 1.0867917e+05, 3.0498162e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.0191308e+05, 1.1059411e+05, 2.2916095e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.0067196e+05, 9.1790610e+04, 2.4974455e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 9.3863750e+04, 1.2732038e+05, 2.4983944e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 9.1992390e+04, 1.3549507e+05, 2.5266493e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.1994324e+05, 1.5654742e+05, 2.5651292e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.1452361e+05, 1.2261684e+05, 2.6177623e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.8013110e+04, 1.2159755e+05, 2.6434606e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 9.4657160e+04, 1.4507758e+05, 2.8257431e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 9.1749160e+04, 1.1417579e+05, 2.9491957e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 8.6419700e+04, 1.5351411e+05, 0.0000000e+00,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.6253860e+04, 1.1386730e+05, 2.9866447e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 7.8389470e+04, 1.5377343e+05, 2.9973729e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.3994560e+04, 1.2278275e+05, 3.0331926e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.7532530e+04, 1.0575103e+05, 3.0476873e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.7044010e+04, 9.9281340e+04, 1.4057481e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.4664710e+04, 1.3955316e+05, 1.3796262e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 7.5328870e+04, 1.4413598e+05, 1.3405007e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.2107600e+04, 1.2786455e+05, 3.5318381e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.6051520e+04, 1.8264556e+05, 1.1814820e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.5605480e+04, 1.5303206e+05, 1.0713838e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.1994480e+04, 1.1564128e+05, 9.1131240e+04,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.1136380e+04, 1.5270192e+05, 8.8218230e+04,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.3408860e+04, 1.2921961e+05, 4.6085250e+04,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 5.5493950e+04, 1.0305749e+05, 2.1463481e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 4.6426070e+04, 1.5769392e+05, 2.1079767e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 4.6014020e+04, 8.5047440e+04, 2.0551764e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 2.8663760e+04, 1.2705621e+05, 2.0112682e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 4.4069950e+04, 5.1283140e+04, 1.9702942e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 2.0229590e+04, 6.5947930e+04, 1.8526510e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 3.8558510e+04, 8.2982090e+04, 1.7499930e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 2.8754330e+04, 1.1854605e+05, 1.7279567e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 2.7892920e+04, 8.4710770e+04, 1.6447071e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 2.3640930e+04, 9.6189630e+04, 1.4800111e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.5505730e+04, 1.2738230e+05, 3.5534170e+04,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 2.2177740e+04, 1.5480614e+05, 2.8334720e+04,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.0002300e+03, 1.2415304e+05, 1.9039300e+03,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.3154600e+03, 1.1581621e+05, 2.9711446e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.3542692e+05, 0.0000000e+00,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 5.4205000e+02, 5.1743150e+04, 0.0000000e+00,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.1698380e+05, 4.5173060e+04,\n",
       "        1.0000000e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.append( arr=np.ones((size, 1)).astype(int), values=X, axis=1 )\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.6534920e+05, 1.3689780e+05, 4.7178410e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.6259770e+05, 1.5137759e+05, 4.4389853e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.5344151e+05, 1.0114555e+05, 4.0793454e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.4437241e+05, 1.1867185e+05, 3.8319962e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.4210734e+05, 9.1391770e+04, 3.6616842e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.3187690e+05, 9.9814710e+04, 3.6286136e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.3461546e+05, 1.4719887e+05, 1.2771682e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.3029813e+05, 1.4553006e+05, 3.2387668e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.2054252e+05, 1.4871895e+05, 3.1161329e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.2333488e+05, 1.0867917e+05, 3.0498162e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.0191308e+05, 1.1059411e+05, 2.2916095e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.0067196e+05, 9.1790610e+04, 2.4974455e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 9.3863750e+04, 1.2732038e+05, 2.4983944e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 9.1992390e+04, 1.3549507e+05, 2.5266493e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.1994324e+05, 1.5654742e+05, 2.5651292e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.1452361e+05, 1.2261684e+05, 2.6177623e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.8013110e+04, 1.2159755e+05, 2.6434606e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 9.4657160e+04, 1.4507758e+05, 2.8257431e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 9.1749160e+04, 1.1417579e+05, 2.9491957e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 8.6419700e+04, 1.5351411e+05, 0.0000000e+00,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.6253860e+04, 1.1386730e+05, 2.9866447e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 7.8389470e+04, 1.5377343e+05, 2.9973729e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.3994560e+04, 1.2278275e+05, 3.0331926e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.7532530e+04, 1.0575103e+05, 3.0476873e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.7044010e+04, 9.9281340e+04, 1.4057481e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.4664710e+04, 1.3955316e+05, 1.3796262e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 7.5328870e+04, 1.4413598e+05, 1.3405007e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 7.2107600e+04, 1.2786455e+05, 3.5318381e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.6051520e+04, 1.8264556e+05, 1.1814820e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.5605480e+04, 1.5303206e+05, 1.0713838e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.1994480e+04, 1.1564128e+05, 9.1131240e+04,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.1136380e+04, 1.5270192e+05, 8.8218230e+04,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 6.3408860e+04, 1.2921961e+05, 4.6085250e+04,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 5.5493950e+04, 1.0305749e+05, 2.1463481e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 4.6426070e+04, 1.5769392e+05, 2.1079767e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 4.6014020e+04, 8.5047440e+04, 2.0551764e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 2.8663760e+04, 1.2705621e+05, 2.0112682e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 4.4069950e+04, 5.1283140e+04, 1.9702942e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 2.0229590e+04, 6.5947930e+04, 1.8526510e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 3.8558510e+04, 8.2982090e+04, 1.7499930e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 2.8754330e+04, 1.1854605e+05, 1.7279567e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 2.7892920e+04, 8.4710770e+04, 1.6447071e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 2.3640930e+04, 9.6189630e+04, 1.4800111e+05,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.5505730e+04, 1.2738230e+05, 3.5534170e+04,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 2.2177740e+04, 1.5480614e+05, 2.8334720e+04,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 1.0002300e+03, 1.2415304e+05, 1.9039300e+03,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 1.3154600e+03, 1.1581621e+05, 2.9711446e+05,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.3542692e+05, 0.0000000e+00,\n",
       "        1.0000000e+00],\n",
       "       [1.0000000e+00, 5.4205000e+02, 5.1743150e+04, 0.0000000e+00,\n",
       "        0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.1698380e+05, 4.5173060e+04,\n",
       "        1.0000000e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Créons une matrice X_optimale qui contiuendra les variables qui apportent une importance siginificative a notre modele\n",
    "\n",
    "X_optimale = X[:, [0, 1, 2, 3, 4]] #Recuperer toutes les colonnes du dataset X\n",
    "X_optimale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#+\\nThis function performs Ordinary Least Squares (OLS) regression using the statsmodels library.#+\\n#+\\nParameters:#+\\n- endog (array-like): The dependent variable, a 1-D array-like object.#+\\n- exog (array-like): The independent variables, a 2-D array-like object.#+\\n#+\\nReturns:#+\\n- regressor_OLS: An instance of the statsmodels.regression.linear_model.OLS class, which represents the OLS regression model.#+\\n#+\\nThe function takes the endogenous (dependent) variable 'Y' and the exogenous (independent) variables 'X_optimale' as input and fits an OLS regression model.#+\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"#+\n",
    "This function performs Ordinary Least Squares (OLS) regression using the statsmodels library.#+\n",
    "#+\n",
    "Parameters:#+\n",
    "- endog (array-like): The dependent variable, a 1-D array-like object.#+\n",
    "- exog (array-like): The independent variables, a 2-D array-like object.#+\n",
    "#+\n",
    "Returns:#+\n",
    "- regressor_OLS: An instance of the statsmodels.regression.linear_model.OLS class, which represents the OLS regression model.#+\n",
    "#+\n",
    "The function takes the endogenous (dependent) variable 'Y' and the exogenous (independent) variables 'X_optimale' as input and fits an OLS regression model.#+\n",
    "\"\"\"#+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>BackWard Elimination </br><h2>Étape 1</h2></br><h3>Selectionner les seuil SL(exemple : SL =0.05) en dessous du quel on conserve une variable dans le model</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>BackWard Elimination </br><h2>Étape 2</h2></br><h3>Entrainer le model avec tous les predicteurs possibles</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "regressor_OLS = sm.OLS(endog=Y, exog=X_optimale).fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>BackWard Elimination </br><h2>Étape 3</h2></br><h3>Conserver le prédicteur avec la plus grande P-value, si P > SL aller a l'etape 4 sinon Aller a l'etape 5</br> P ici est la probabilité que le coefficient d'une variable soit nul </h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>lun, 03 mar 2025</td> <th>  Prob (F-statistic):</th> <td>8.51e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:44:24</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.016e+04</td> <td> 6798.992</td> <td>    7.377</td> <td> 0.000</td> <td> 3.65e+04</td> <td> 6.39e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.046</td> <td>   17.646</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.052</td> <td>   -0.520</td> <td> 0.606</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.017</td> <td>    1.627</td> <td> 0.111</td> <td>   -0.006</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>  -70.2265</td> <td> 2828.752</td> <td>   -0.025</td> <td> 0.980</td> <td>-5767.625</td> <td> 5627.172</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.785</td> <th>  Durbin-Watson:     </th> <td>   1.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.568</td> <th>  Cond. No.          </th> <td>1.44e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.44e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.946   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     217.2   \\\\\n",
       "\\textbf{Date:}             & lun, 03 mar 2025 & \\textbf{  Prob (F-statistic):} &  8.51e-29   \\\\\n",
       "\\textbf{Time:}             &     14:44:24     & \\textbf{  Log-Likelihood:    } &   -525.39   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1061.   \\\\\n",
       "\\textbf{Df Residuals:}     &          45      & \\textbf{  BIC:               } &     1070.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.016e+04  &     6798.992     &     7.377  &         0.000        &     3.65e+04    &     6.39e+04     \\\\\n",
       "\\textbf{x1}    &       0.8057  &        0.046     &    17.646  &         0.000        &        0.714    &        0.898     \\\\\n",
       "\\textbf{x2}    &      -0.0268  &        0.052     &    -0.520  &         0.606        &       -0.131    &        0.077     \\\\\n",
       "\\textbf{x3}    &       0.0272  &        0.017     &     1.627  &         0.111        &       -0.006    &        0.061     \\\\\n",
       "\\textbf{x4}    &     -70.2265  &     2828.752     &    -0.025  &         0.980        &    -5767.625    &     5627.172     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.785 & \\textbf{  Durbin-Watson:     } &    1.281  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.242  \\\\\n",
       "\\textbf{Skew:}          & -0.949 & \\textbf{  Prob(JB):          } & 2.44e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.568 & \\textbf{  Cond. No.          } & 1.44e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.44e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                lun, 03 mar 2025   Prob (F-statistic):           8.51e-29\n",
       "Time:                        14:44:24   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.016e+04   6798.992      7.377      0.000    3.65e+04    6.39e+04\n",
       "x1             0.8057      0.046     17.646      0.000       0.714       0.898\n",
       "x2            -0.0268      0.052     -0.520      0.606      -0.131       0.077\n",
       "x3             0.0272      0.017      1.627      0.111      -0.006       0.061\n",
       "x4           -70.2265   2828.752     -0.025      0.980   -5767.625    5627.172\n",
       "==============================================================================\n",
       "Omnibus:                       14.785   Durbin-Watson:                   1.281\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.242\n",
       "Skew:                          -0.949   Prob(JB):                     2.44e-05\n",
       "Kurtosis:                       5.568   Cond. No.                     1.44e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.44e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary() #Permet de retourner les tableaux de caracteristiques a l'interieur de laquelle on identifiera les p-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le trableau fournit par cette methode (regressor_OLS.summary()) \n",
    "\n",
    "- la ligne \"const\" represente celle que l'on a ajouter dans notre dataset(X) en premiere colonne.\n",
    "\n",
    "- les Xi sont les variables dans le meme ordre que dans le dataset\n",
    "\n",
    "- la colonne P > |t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>BackWard Elimination </br><h2>Étape 4</h2></br><h3>Retirer la variable dont la P-value est superieur au seuil dans le jeu de données.</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirer la variable X4 car sa p value est de 0.980\t> 0.05\n",
    "\n",
    "X_optimale = X[:, [0, 1, 2, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>BackWard Elimination </br><h2>Étape 5</h2></br><h3>Entrainer le model sans la variable don le P > SL</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog=Y, exog=X_optimale).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>lun, 03 mar 2025</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:45:26</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     296.0   \\\\\n",
       "\\textbf{Date:}             & lun, 03 mar 2025 & \\textbf{  Prob (F-statistic):} &  4.53e-30   \\\\\n",
       "\\textbf{Time:}             &     14:45:26     & \\textbf{  Log-Likelihood:    } &   -525.39   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          46      & \\textbf{  BIC:               } &     1066.   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.012e+04  &     6572.353     &     7.626  &         0.000        &     3.69e+04    &     6.34e+04     \\\\\n",
       "\\textbf{x1}    &       0.8057  &        0.045     &    17.846  &         0.000        &        0.715    &        0.897     \\\\\n",
       "\\textbf{x2}    &      -0.0268  &        0.051     &    -0.526  &         0.602        &       -0.130    &        0.076     \\\\\n",
       "\\textbf{x3}    &       0.0272  &        0.016     &     1.655  &         0.105        &       -0.006    &        0.060     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.838 & \\textbf{  Durbin-Watson:     } &    1.282  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.442  \\\\\n",
       "\\textbf{Skew:}          & -0.949 & \\textbf{  Prob(JB):          } & 2.21e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.586 & \\textbf{  Cond. No.          } & 1.40e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                lun, 03 mar 2025   Prob (F-statistic):           4.53e-30\n",
       "Time:                        14:45:26   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>BackWard Elimination </br><h2>Étape 4</h2></br><h3>Retirer la variable dont la P-value est superieur au seuil dans le jeu de données.</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirer la variable X2 car sa p value est de 0.606\t> 0.05\n",
    "\n",
    "X_optimale = X[:, [0, 1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>lun, 03 mar 2025</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:48:30</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.950   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     450.8   \\\\\n",
       "\\textbf{Date:}             & lun, 03 mar 2025 & \\textbf{  Prob (F-statistic):} &  2.16e-31   \\\\\n",
       "\\textbf{Time:}             &     14:48:30     & \\textbf{  Log-Likelihood:    } &   -525.54   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1057.   \\\\\n",
       "\\textbf{Df Residuals:}     &          47      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.698e+04  &     2689.933     &    17.464  &         0.000        &     4.16e+04    &     5.24e+04     \\\\\n",
       "\\textbf{x1}    &       0.7966  &        0.041     &    19.266  &         0.000        &        0.713    &        0.880     \\\\\n",
       "\\textbf{x2}    &       0.0299  &        0.016     &     1.927  &         0.060        &       -0.001    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.677 & \\textbf{  Durbin-Watson:     } &    1.257  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.161  \\\\\n",
       "\\textbf{Skew:}          & -0.939 & \\textbf{  Prob(JB):          } & 2.54e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.575 & \\textbf{  Cond. No.          } & 5.32e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 5.32e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                lun, 03 mar 2025   Prob (F-statistic):           2.16e-31\n",
       "Time:                        14:48:30   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS = sm.OLS(endog=Y, exog=X_optimale).fit()\n",
    "\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on peut eliminer la variable X2 car sa P-value est 0.06 > 0.05 mais laissons la histoire de pratique, Ainsi la combinaison des variables qui permettent de bien predire les profit est composé des variables X1(R&D Spend) et X2(Marketing Spend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_optimale, Y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "finalRegressor = LinearRegression()\n",
    "\n",
    "finalRegressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([102233.23565958, 133606.98920513, 133949.0507749 ,  73572.88757331,\n",
       "       180116.44892447, 114279.85967514,  68172.55388282,  97431.12261484])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_Y_predict = finalRegressor.predict(X_test)\n",
    "final_Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82075053.37708801"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_score = mean_squared_error(y_test, final_Y_predict)\n",
    "new_score #Nous voyons que le taux d'erreur a diminué"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
